name: unified

# Relative benchmark path under `task.benchmark_root` (default: benchmarks/).
# Example: KernelEngineering/TriMul
benchmark: null
benchmark_root: benchmarks

# Metadata folder inside benchmark directory.
metadata_dir: frontier_eval

# Initial candidate source path (relative to benchmark dir).
# If null, loader reads `<metadata_dir>/initial_program.txt`.
initial_program: null
initial_program_file: initial_program.txt

# Destination path (in sandbox benchmark) where evolved candidate is written.
# If null, defaults to `initial_program`.
candidate_destination: null
candidate_destination_file: candidate_destination.txt

# Benchmark execution command.
# Supports placeholders:
#   {python}, {candidate}, {benchmark}, {sandbox}, {repo_root}, {benchmark_source}, {benchmark_id}
# and raw variants: {python_raw}, {candidate_raw}, ...
eval_command: null
eval_command_file: eval_command.txt

# Working directory for eval command (relative to benchmark root in sandbox).
eval_cwd: .
eval_cwd_file: eval_cwd.txt

# Agent-facing context files (relative to benchmark dir).
# Can be set inline and/or via `<metadata_dir>/agent_files.txt`.
agent_files: []
agent_files_file: agent_files.txt

# Files/dirs copied into sandbox before evaluation.
# Empty means "copy full benchmark dir".
copy_files: []
copy_files_file: copy_files.txt

# Optional read-only files/dirs checked before/after eval run.
readonly_files: []
readonly_files_file: readonly_files.txt

# Optional prompt/constraint text (for artifacts and LLM context).
constraints_text: null
constraints_file: constraints.txt

# Optional JSON outputs generated by benchmark evaluator script.
# Set null to disable.
metrics_json: metrics.json
artifacts_json: artifacts.json

# When true and metrics_json is missing, parse last JSON object in stdout.
parse_stdout_json: true

# Optional hard cap for unified evaluator itself; still bounded by
# FRONTIER_EVAL_EVALUATOR_TIMEOUT_S from algorithm side.
timeout_s: null

runtime:
  # If set, {python} resolves to this path and conda-run is disabled.
  python_path: ${oc.env:FRONTIER_EVAL_UNIFIED_PYTHON,}
  # Used when python_path is empty and use_conda_run=true.
  conda_env: ${oc.env:FRONTIER_EVAL_UNIFIED_CONDA_ENV,frontier-eval-2}
  use_conda_run: true
  shell: bash
  env: {}
