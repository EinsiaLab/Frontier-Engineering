# Open Problems in Single-Cell Analysis: Denoising Benchmark v1.0.0

## üéØ Task Background

While single-cell RNA sequencing (scRNA-seq) is a powerful technology, current sequencing protocols can typically only detect a small fraction of the mRNA molecules present in each individual cell. This extremely low capture rate results in observed measurements (UMI counts) being accompanied by significant **technical noise**. In the data matrix, this is manifested as a vast number of "zero" values, commonly referred to as **"dropout"** or **technical zeros**. This highly sparse and noisy data severely hinders downstream biological analyses, such as cell clustering, trajectory inference, and differential expression analysis.

## üìù Task Description

The core objective of the **denoising** task is to estimate the **true expression levels** of each gene in each cell from the noisy and sparse observed data. In single-cell literature, this task is often referred to as **"imputation."**

**Core Challenge**: The primary obstacle in evaluating denoising methods is the **lack of a ground truth reference**. It is impossible to know the absolute mRNA count within a cell without destroying it. To address this, the current benchmark utilizes an innovative self-supervised evaluation framework called **Molecular Cross-Validation (MCV)**. MCV works by randomly partitioning observed molecules into a training set and a testing set. It has been proven both theoretically and practically that the quantified denoising accuracy using MCV aligns closely with accuracy measurements where ground truth is available. Your goal is to optimize based on this framework or create a new algorithm to improve accuracy.

## üì• Input & Output Definitions
- Input: A sparse scRNA-seq raw count matrix $X \in \mathbb{N}^{C \times G}$, where $C$ is the number of cells and $G$ is the number of genes. Elements in the matrix are observed UMI counts (containing high technical noise and dropouts).
- Output: A denoised dense expression matrix $\hat{X} \in \mathbb{R}^{C \times G}$. Elements represent the algorithm's estimate of the true expression level or the denoised relative abundance of a gene in a specific cell.

## üìä Evaluation Metrics
Under the MCV framework, the denoised matrix generated by the model based on the training set is compared directly against the held-out test set. This benchmark primarily utilizes two metrics:
1. **Mean Squared Error (MSE)**: Measures the average squared difference between the denoised predicted values and the observed values in the test set. The formula is:$$MSE = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2$$where $y_i$ is the observed count in the test set, $\hat{y}_i$ is the model's denoised prediction, and $N$ is the total number of elements in the matrix. A lower MSE indicates that the predicted values are closer to the observed distribution.
2. **Poisson Loss**: Since scRNA-seq UMI counts are theoretically expected to follow a Poisson distribution, Poisson loss measures the goodness-of-fit by calculating the negative log-likelihood. The formula (simplified single-point version) is:$$L_{Poisson} = \hat{y}_i - y_i \log(\hat{y}_i)$$This metric better penalizes prediction biases in low-expression count regions. A lower score indicates that the denoising effect is more consistent with the statistical properties of the data.

## üèÜ Existing Method Benchmarking Results

This benchmark evaluated 11 mainstream denoising methods and their variants across 3 different datasets (1k PBMC, Pancreas inDrop, Tabula Muris Senis Lung).

**Resource & Performance Summary Table:**

| Method | Overall Performance | MSE Performance | Poisson Loss Performance | Peak Memory | Runtime |
| --- | --- | --- | --- | --- | --- |
| **Perfect denoising** (Upper Bound) | 1.00 | 1.00 | 1.00 | 2G | 8m |
| **MAGIC** (and variants) | **Excellent** (~0.41-0.61) | **Excellent** (~0.24) | **Excellent** (~0.59-0.98) | ~465M - 490M | 9m - 18m |
| **ALRA** (and variants) | Good (~0.48) | Neutral (-0.01) | **Excellent** (~0.98) | ~465M | 44m - 47m |
| **DCA** (Deep Count Autoencoder) | Fair (~0.02) | Good (~0.12) | Poor (-0.08) | ~960M | 13m |
| **KNN smoothing** | Poor (0.00) | Neutral (~0.08) | Poor (-0.08) | ~464M | 10m |
| **Iterative KNN smoothing** | Very Poor (-5.10) | Neutral (~0.09) | Very Poor (-10.30) | ~485M | 44m |
| **No denoising** (Lower Bound) | 0.00 | 0.00 | 0.00 | 2G | 8m |

*(Note: Scores are normalized relative values, where 1.0 represents the theoretical optimum, 0.0 represents the baseline without processing, and negative values indicate that denoising introduced more error than doing nothing at all.)*